{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcc3c054",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T21:03:37.179723Z",
     "iopub.status.busy": "2025-02-17T21:03:37.179485Z",
     "iopub.status.idle": "2025-02-17T21:04:55.667320Z",
     "shell.execute_reply": "2025-02-17T21:04:55.666386Z"
    },
    "papermill": {
     "duration": 78.49457,
     "end_time": "2025-02-17T21:04:55.670416",
     "exception": false,
     "start_time": "2025-02-17T21:03:37.175846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split complete! ✅\n",
      "Train contains 7 classes.\n",
      "Validation contains 7 classes.\n",
      "Test contains 7 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Read-only dataset path\n",
    "dataset_dir = \"/kaggle/input/oct-images-dataset/\"  # Change this to your dataset path\n",
    "writable_dir = \"/kaggle/working/dataset\"  # Writable directory\n",
    "\n",
    "# Copy dataset to a writable location\n",
    "if not os.path.exists(writable_dir):\n",
    "    shutil.copytree(dataset_dir, writable_dir)\n",
    "\n",
    "# Define train, val, test directories\n",
    "train_dir = os.path.join(writable_dir, \"train\")\n",
    "val_dir = os.path.join(writable_dir, \"val\")\n",
    "test_dir = os.path.join(writable_dir, \"test\")\n",
    "\n",
    "# Create train, val, test directories\n",
    "for directory in [train_dir, val_dir, test_dir]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Get all subfolders (classes)\n",
    "subfolders = [f for f in os.listdir(writable_dir) if os.path.isdir(os.path.join(writable_dir, f))]\n",
    "\n",
    "# Process each class folder separately\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(writable_dir, subfolder)\n",
    "\n",
    "    # Get all images in this class\n",
    "    all_images = [f for f in os.listdir(subfolder_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    random.shuffle(all_images)  # Shuffle before splitting\n",
    "\n",
    "    # Define split sizes\n",
    "    train_split = int(0.7 * len(all_images))\n",
    "    val_split = int(0.9 * len(all_images))  # 70% train, next 20% val, last 10% test\n",
    "\n",
    "    # Create class-specific subdirectories\n",
    "    os.makedirs(os.path.join(train_dir, subfolder), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_dir, subfolder), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir, subfolder), exist_ok=True)\n",
    "\n",
    "    # Move images to respective folders\n",
    "    for i, img in enumerate(all_images):\n",
    "        src_path = os.path.join(subfolder_path, img)\n",
    "\n",
    "        if i < train_split:\n",
    "            dest_path = os.path.join(train_dir, subfolder, img)\n",
    "        elif i < val_split:\n",
    "            dest_path = os.path.join(val_dir, subfolder, img)\n",
    "        else:\n",
    "            dest_path = os.path.join(test_dir, subfolder, img)\n",
    "\n",
    "        shutil.move(src_path, dest_path)\n",
    "\n",
    "print(f\"Dataset split complete! ✅\")\n",
    "print(f\"Train contains {len(os.listdir(train_dir))} classes.\")\n",
    "print(f\"Validation contains {len(os.listdir(val_dir))} classes.\")\n",
    "print(f\"Test contains {len(os.listdir(test_dir))} classes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1802500e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T21:04:55.676578Z",
     "iopub.status.busy": "2025-02-17T21:04:55.676281Z",
     "iopub.status.idle": "2025-02-17T21:11:34.584153Z",
     "shell.execute_reply": "2025-02-17T21:11:34.582923Z"
    },
    "papermill": {
     "duration": 398.912233,
     "end_time": "2025-02-17T21:11:34.585426",
     "exception": true,
     "start_time": "2025-02-17T21:04:55.673193",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15301 files belonging to 7 classes.\n",
      "Found 4372 files belonging to 7 classes.\n",
      "Found 2188 files belonging to 7 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Epoch 1/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 57ms/step - accuracy: 0.5597 - loss: 1.1378 - val_accuracy: 0.7207 - val_loss: 0.7989\n",
      "Epoch 2/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 32ms/step - accuracy: 0.7047 - loss: 0.8421 - val_accuracy: 0.7493 - val_loss: 0.7100\n",
      "Epoch 3/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 33ms/step - accuracy: 0.7329 - loss: 0.7659 - val_accuracy: 0.7587 - val_loss: 0.6789\n",
      "Epoch 4/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 33ms/step - accuracy: 0.7378 - loss: 0.7339 - val_accuracy: 0.7644 - val_loss: 0.6583\n",
      "Epoch 5/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 34ms/step - accuracy: 0.7458 - loss: 0.7102 - val_accuracy: 0.7621 - val_loss: 0.6606\n",
      "Epoch 6/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 34ms/step - accuracy: 0.7539 - loss: 0.6858 - val_accuracy: 0.7825 - val_loss: 0.6100\n",
      "Epoch 7/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 35ms/step - accuracy: 0.7593 - loss: 0.6652 - val_accuracy: 0.7850 - val_loss: 0.6021\n",
      "Epoch 8/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - accuracy: 0.7691 - loss: 0.6438 - val_accuracy: 0.7896 - val_loss: 0.6050\n",
      "Epoch 9/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - accuracy: 0.7718 - loss: 0.6413 - val_accuracy: 0.7909 - val_loss: 0.5906\n",
      "Epoch 10/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - accuracy: 0.7756 - loss: 0.6285 - val_accuracy: 0.7688 - val_loss: 0.6451\n",
      "Epoch 11/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 35ms/step - accuracy: 0.7731 - loss: 0.6328 - val_accuracy: 0.7928 - val_loss: 0.5785\n",
      "Epoch 12/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 35ms/step - accuracy: 0.7776 - loss: 0.6102 - val_accuracy: 0.7914 - val_loss: 0.5965\n",
      "Epoch 13/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - accuracy: 0.7810 - loss: 0.6075 - val_accuracy: 0.7818 - val_loss: 0.6036\n",
      "Epoch 14/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - accuracy: 0.7820 - loss: 0.6013 - val_accuracy: 0.7985 - val_loss: 0.5602\n",
      "Epoch 15/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - accuracy: 0.7896 - loss: 0.5898 - val_accuracy: 0.7900 - val_loss: 0.5810\n",
      "Epoch 16/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 35ms/step - accuracy: 0.7939 - loss: 0.5875 - val_accuracy: 0.7941 - val_loss: 0.5656\n",
      "Epoch 17/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 35ms/step - accuracy: 0.7890 - loss: 0.5798 - val_accuracy: 0.7985 - val_loss: 0.5672\n",
      "Epoch 18/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - accuracy: 0.7954 - loss: 0.5669 - val_accuracy: 0.7896 - val_loss: 0.5919\n",
      "Epoch 19/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - accuracy: 0.7945 - loss: 0.5659 - val_accuracy: 0.7957 - val_loss: 0.5809\n",
      "Epoch 20/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - accuracy: 0.8005 - loss: 0.5545 - val_accuracy: 0.7999 - val_loss: 0.5661\n",
      "✅ Model saved successfully!\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.8011 - loss: 0.5539\n",
      "Test Accuracy: 0.7893\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 4, does not match size of target_names, 7. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f5a145a55cf9>\u001b[0m in \u001b[0;36m<cell line: 80>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2330\u001b[0m             )\n\u001b[1;32m   2331\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2333\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 4, does not match size of target_names, 7. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "# UGG16 X ResNet Hybrid Model for classification: Higher accuracy score, so kept\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from PIL import Image\n",
    "\n",
    "data_dir = \"/kaggle/working/dataset\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "val_dir = os.path.join(data_dir, \"val\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "image_size = (64, 64)\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir, image_size=image_size, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "val_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    val_dir, image_size=image_size, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "test_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir, image_size=image_size, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "class_names = train_dataset.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "train_dataset = train_dataset.map(lambda x, y: ((normalization_layer(x), normalization_layer(x)), y))\n",
    "val_dataset = val_dataset.map(lambda x, y: ((normalization_layer(x), normalization_layer(x)), y))\n",
    "test_dataset = test_dataset.map(lambda x, y: ((normalization_layer(x), normalization_layer(x)), y))\n",
    "\n",
    "vgg16 = keras.applications.VGG16(weights=\"imagenet\", include_top=False, input_shape=(64, 64, 3))\n",
    "vgg16.trainable = False\n",
    "\n",
    "resnet50 = keras.applications.ResNet50(weights=\"imagenet\", include_top=False, input_shape=(64, 64, 3))\n",
    "resnet50.trainable = False\n",
    "vgg16_output = layers.Flatten()(vgg16.output)\n",
    "resnet50_output = layers.Flatten()(resnet50.output)\n",
    "\n",
    "merged = layers.concatenate([vgg16_output, resnet50_output])\n",
    "\n",
    "x = layers.Dense(512, activation=\"relu\")(merged)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "output = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=[vgg16.input, resnet50.input], outputs=output)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "model.save(\"Hybrid_VGG16_ResNet50.h5\")\n",
    "print(\"✅ Model saved successfully!\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "for images, labels in test_dataset:\n",
    "    preds = model.predict(images)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "def predict_image(image_path, model):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = image.resize((64, 64))\n",
    "    image = np.array(image) / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    prediction = model.predict((image, image))\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    return class_names[predicted_class]\n",
    "\n",
    "image_path = r\"C:\\Users\\91995\\Downloads\\DRUSEN-1001666-5.jpeg\"\n",
    "prediction = predict_image(image_path, model)\n",
    "print(f\"Predicted Class: {prediction}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017f6acb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T20:00:49.183267Z",
     "iopub.status.busy": "2025-02-17T20:00:49.182923Z",
     "iopub.status.idle": "2025-02-17T20:06:34.581112Z",
     "shell.execute_reply": "2025-02-17T20:06:34.580189Z",
     "shell.execute_reply.started": "2025-02-17T20:00:49.183241Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=20\n",
    ")\n",
    "model.save(\"Hybrid_VGG16_ResNet50.h5\")\n",
    "print(\"✅ Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff0e69a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T20:07:09.813056Z",
     "iopub.status.busy": "2025-02-17T20:07:09.812747Z",
     "iopub.status.idle": "2025-02-17T20:24:21.617903Z",
     "shell.execute_reply": "2025-02-17T20:24:21.617131Z",
     "shell.execute_reply.started": "2025-02-17T20:07:09.813004Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history2 = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=60\n",
    ")\n",
    "model.save(\"Hybrid_VGG16_ResNet50.h5\")\n",
    "print(\"✅ Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98d4ed1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T20:30:40.750841Z",
     "iopub.status.busy": "2025-02-17T20:30:40.750539Z",
     "iopub.status.idle": "2025-02-17T20:30:41.589733Z",
     "shell.execute_reply": "2025-02-17T20:30:41.588653Z",
     "shell.execute_reply.started": "2025-02-17T20:30:40.750816Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(\"OCT_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc8fa5d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**CHECKING FOR ANOTHER MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18529166",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T20:37:56.063673Z",
     "iopub.status.busy": "2025-02-17T20:37:56.063351Z",
     "iopub.status.idle": "2025-02-17T20:52:30.089464Z",
     "shell.execute_reply": "2025-02-17T20:52:30.088309Z",
     "shell.execute_reply.started": "2025-02-17T20:37:56.063648Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "# from PIL import Image\n",
    "\n",
    "# # Load dataset\n",
    "# data_dir = \"/kaggle/working/dataset\"\n",
    "# train_dir = os.path.join(data_dir, \"train\")\n",
    "# val_dir = os.path.join(data_dir, \"val\")\n",
    "# test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "# image_size = (64, 64)\n",
    "# batch_size = 32\n",
    "\n",
    "# train_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "#     train_dir, image_size=image_size, batch_size=batch_size, shuffle=True\n",
    "# )\n",
    "\n",
    "# val_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "#     val_dir, image_size=image_size, batch_size=batch_size, shuffle=False\n",
    "# )\n",
    "\n",
    "# test_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "#     test_dir, image_size=image_size, batch_size=batch_size, shuffle=False\n",
    "# )\n",
    "\n",
    "# class_names = train_dataset.class_names\n",
    "# num_classes = len(class_names)\n",
    "\n",
    "# # Apply normalization\n",
    "# normalization_layer = layers.Rescaling(1./255)\n",
    "# train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "# val_dataset = val_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "# test_dataset = test_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "# # Load VGG16 & ResNet50\n",
    "# vgg16 = keras.applications.VGG16(weights=\"imagenet\", include_top=False, input_shape=(64, 64, 3))\n",
    "# resnet50 = keras.applications.ResNet50(weights=\"imagenet\", include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "# vgg16.trainable = False\n",
    "# resnet50.trainable = False\n",
    "\n",
    "# # Define Inputs\n",
    "# input_layer = keras.Input(shape=(64, 64, 3))\n",
    "\n",
    "# # Pass input through both models\n",
    "# vgg16_features = vgg16(input_layer)\n",
    "# resnet50_features = resnet50(input_layer)\n",
    "\n",
    "# # Global pooling to reduce dimensionality\n",
    "# vgg16_output = layers.GlobalAveragePooling2D()(vgg16_features)\n",
    "# resnet50_output = layers.GlobalAveragePooling2D()(resnet50_features)\n",
    "\n",
    "# # Concatenate outputs\n",
    "# merged = layers.concatenate([vgg16_output, resnet50_output])\n",
    "\n",
    "# # Fully Connected Layers\n",
    "# x = layers.Dense(512, activation=\"relu\")(merged)\n",
    "# x = layers.Dropout(0.5)(x)\n",
    "# x = layers.Dense(256, activation=\"relu\")(x)\n",
    "# x = layers.Dense(128, activation=\"relu\")(x)\n",
    "# output = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "# # Define Model with a single input layer\n",
    "# model = keras.Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "# # Compile Model\n",
    "# model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "#               loss=\"sparse_categorical_crossentropy\",\n",
    "#               metrics=[\"accuracy\"])\n",
    "\n",
    "# # Train Model\n",
    "# history = model.fit(\n",
    "#     train_dataset,\n",
    "#     validation_data=val_dataset,\n",
    "#     epochs=50\n",
    "# )\n",
    "\n",
    "# # Save Model\n",
    "# model.save(\"Hybrid_VGG16_ResNet50.h5\")\n",
    "# print(\"✅ Model saved successfully!\")\n",
    "\n",
    "# # Evaluate Model\n",
    "# test_loss, test_acc = model.evaluate(test_dataset)\n",
    "# print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# # Predictions & Confusion Matrix\n",
    "# y_true, y_pred = [], []\n",
    "# for images, labels in test_dataset:\n",
    "#     preds = model.predict(images)\n",
    "#     y_true.extend(labels.numpy())\n",
    "#     y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "# print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "# cm = confusion_matrix(y_true, y_pred)\n",
    "# plt.figure(figsize=(6, 5))\n",
    "# sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "# plt.xlabel(\"Predicted\")\n",
    "# plt.ylabel(\"True\")\n",
    "# plt.title(\"Confusion Matrix\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e60e2de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T20:52:50.045874Z",
     "iopub.status.busy": "2025-02-17T20:52:50.045551Z",
     "iopub.status.idle": "2025-02-17T20:59:47.913746Z",
     "shell.execute_reply": "2025-02-17T20:59:47.912780Z",
     "shell.execute_reply.started": "2025-02-17T20:52:50.045845Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fece1c7c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6686403,
     "sourceId": 10776667,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 482.952523,
   "end_time": "2025-02-17T21:11:37.566106",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-17T21:03:34.613583",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
